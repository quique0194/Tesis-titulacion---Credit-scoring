\chapter{Experimentos y Resultados}


\section{Experimentos}

En esta sección se describirán los experimentos llevados a cabo.

\subsection{Experimento 1}

El primer paso es hacer una comparación entre los clasificadores individuales y los \ac{ECDD}. El objetivo de este experimento es verificar si efectivamente el desempeño mejora individualmente por cada clasificador, sin hacer una comparación transversal entre clasificadores de distintas familias.

En este experimento también se usó un algoritmo de aprendizaje profundo: \ac{DBN}.

\subsection{Experimento 2}

En este experimento compararemos los \ac{ECDD} con dos algoritmos de \textit{bagging} usados ampliamente en la actualidad: \ac{RF} y \ac{XGBoost}. El objectivo de este experimento es verificar que el método de \ac{ECDD} es competitivo con otros métodos de ensamble del estado del arte, sin el sesgo de haber usado una metodología diferente para el entrenamiento y la evaluación de los modelos.

\subsection{Experimento 3}

Finalmente en el experimento 3 compararemos los resultados obtenidos por nuestros \ac{ECDD} con los resultados obtenidos en otros estudios del estado del arte que usan los mismos conjuntos de datos. El objetivo de este experimento es ratificar que los resultados son válidos para el estado del arte usando dos conjuntos de datos referenciales.


\section{Resultados}

\section{Experimento 1} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Los resultados del experimento 1 se pueden ver en las Tablas \ref{tab:apurata-proc1}, \ref{tab:lc-proc1} y \ref{tab:german-proc1}.

Se ve que en el \ac{AUC}, la precisión y la exactitud mejoran en todos los clasificadores. Particularmente el AUC se incrementa un promedio de 4.30 en Apurata, 2.80 en Lending Club y 1.62 en el Crédito Alemán.

La exhaustividad baja en la mayoría de modelos, ya que existe un balance entre la precisión y la exhaustividad. Y ya que se trató de optimizar la exactitud, indirectamente se optimizó la precisión, de forma que la exhaustividad cayó un poco.

Se desprende también que la potencial mejora que podemos obtener con el método de ensamble para datos desbalanceados depende del clasificador base y del conjunto de datos sobre el cuál se aplica.

Si analizamos cuál fue el algoritmo base más afectado por el \ac{ECDD}, vemos claramente que el árbol de decisión es el ganador. Esto se debe a que individualmente el árbol de decisión es muy sensible al ruido y fácilmente hace overfitting. Sin embargo al ponerlo dentro de un ensamble, su capacidad de generalizar mejora. De hecho es la misma razón por la que los algoritmos de ensamble más poderosos actualmente usan árboles de decisión como su clasificador base.

\subsection{Sobre el aprendizaje profundo}

El caso de la \ac{DBN} es particular. En primer lugar, ajustar los parámetros del modelo resulta complejo, porque son varios parámetros y porque al ser poca información el modelo presenta una tendencia a caer en overfitting. Esto se observa al tener un desempeño impecable con los datos de entrenamiento, pero un desempeño muy inferior con los datos de prueba.

Luego de ajustar cuidadosamente los parámetros de la mejor forma posible, el poder predictivo no es mejor que otros clasificadores base, específicamente es muy similar al de una \ac{MLP} simple. Esto se puede explicar con la baja dimensionalidad de los datos y la poca cantidad de instancias; ya que no se explota la capacidad de reducción de dimensionalidad del modelo y tampoco se hace un entrenamiento adecuado por la escasez de datos.

En conclusión, este clasificador no es adecuado para este problema, y al ser bastante complejo ya de por sí, no se le creó una versión ensamblada.


\begin{table}[]
\centering
\caption{Experimento 1 con conjunto de datos de Apurata}
\label{tab:apurata-proc1}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
LR				& 70.02		& 89.25		& 96.35			& 82.78		\\		% AUC std: 3.55
ECDD-LR			& 72.56		& 89.76		& 95.96			& 82.86		\\		% AUC std: 3.48
				\hline
MLP				& 68.13		& 88.96		& 91.86			& 80.30		\\		% AUC std: 3.58
ECDD-MLP		& 70.61		& 89.64		& 92.30			& 80.61		\\		% AUC std: 3.49
				\hline
AD				& 61.75		& 86.84		& 98.06			& 83.71		\\		% AUC std: 6.34
ECDD-AD			& 68.81		& 89.42		& 92.93			& 80.73		\\		% AUC std: 3.46
				\hline
SVM				& 66.56		& 89.33		& 87.65			& 78.39		\\		% AUC std: 3.61
ECDD-SVM		& 71.70		& 89.81		& 94.44			& 82.04		\\		% AUC std: 3.54
				\hline
DBN				& 67.80		& 88.04		& 91.76			& 79.84		\\		% AUC std: 3.57
				\hline
\end{tabularx}
\end{table}


\begin{table}[]
\centering
\caption{Experimento 1 con conjunto de datos de LendingClub}
\label{tab:lc-proc1}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
LR				& 73.36		& 77.83		& 95.40			& 75.05		\\		% AUC std: 0.21
ECDD-LR			& 73.34		& 77.55		& 96.23			& 74.85		\\		% AUC std: 0.11
				\hline
MLP				& 74.87		& 78.29		& 95.74			& 75.71		\\		% AUC std: 0.18
ECDD-MLP		& 75.67		& 79.09		& 94.07			& 75.82		\\		% AUC std: 0.14
				\hline
AD				& 75.52		& 77.94		& 92.86			& 75.34		\\		% AUC std: 0.56
ECDD-AD			& 80.34		& 81.88		& 89.50			& 78.05		\\		% AUC std: 0.12
				\hline
SVM				& 73.53		& 77.42		& 97.29			& 75.03		\\		% AUC std: 0.19
ECDD-SVM		& 74.41		& 78.29		& 95.91			& 75.00		\\		% AUC std: 0.13
				\hline
DBN				& 75.01		& 78.56		& 94.92			& 75.72		\\		% AUC std: 0.23
				\hline
\end{tabularx}
\end{table}


\begin{table}[]
\centering
\caption{Experimento 1 con conjunto de datos Alemán}
\label{tab:german-proc1}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
LR				& 71.45		& 81.77		& 99.32			& 78.92		\\		% AUC std: 3.12
ECDD-LR			& 71.50		& 81.84		& 98.83			& 78.68		\\		% AUC std: 2.02
				\hline
MLP				& 69.36		& 81.26		& 98.76			& 78.78		\\		% AUC std: 3.63
ECDD-MLP		& 71.61		& 82.44		& 97.08			& 79.00		\\		% AUC std: 2.10
				\hline
AD				& 66.86		& 79.48		& 99.85			& 78.35		\\		% AUC std: 5.52
ECDD-AD			& 71.82		& 82.71		& 96.02			& 79.20		\\		% AUC std: 1.99
				\hline
SVM				& 67.54		& 80.79		& 97.28			& 79.12		\\		% AUC std: 3.34
ECDD-SVM		& 71.49		& 82.27		& 97.88			& 79.35		\\		% AUC std: 2.09
				\hline
DBN				& 66.84		& 80.07		& 97.98			& 78.24		\\		% AUC std: 3.68
				\hline
\end{tabularx}
\end{table}


\section{Experimento 2} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Los resultados del experimento 2 se pueden ver en las Tablas \ref{tab:apurata-proc2}, \ref{tab:lc-proc2} y \ref{tab:german-proc2}. Para comparar estos resultados se realizó una prueba de T de Student desapareada.

El modelo ECDD-LR \textit{(M=$72.56$, SD=$3.21$)} comparado al modelo \ac{RF} \textit{(M=$69.23$, SD=$3.13$)} demostró un \ac{AUC} significativamente mejor, $t(198)=7.47, p=.0001$.

Se observa que el desempeño de los \ac{ECDD} es ligeramente superior al desempeño de \ac{RF} y \ac{XGBoost}. Si comparamos la mejora obtenida por el mejor \ac{ECDD} respecto al mejor entre RF y XGBoost; vemos que el AUC en Apurata incrementa 3.33, en Lending Club mejora 0.50 y en Crédito Alemán aumenta en 0.06.

Lamentablemente no es posible extrapolar estos resultados a otros dominios donde también hayan conjuntos de datos desbalanceados, ya que los conjuntos de datos crediticios además del desbalance poseen otras características que podrían no cumplirse en otros dominios, como la estacionalidad de los datos, la baja cantidad de features y la información parcialmente oculta. De modo que no podemos afirmar que estos \ac{ECDD} son universalmente mejores que Random Forest y XGBoost.

Otra observación interesante es el buen desempeño que obtiene la Regresión Logística en el conjunto de Apurata. Esto podría indicar que la información es linealmente separable y los otros modelos sufren de un poco de overfitting, razón por la cuál su desempeño no es óptimo.

Finalmente, el \ac{ECDD} de árboles de decisión obtiene resultados muy buenos consistentemente en Lending Club y el Crédito Alemán, lo que sugiere que si los datos no son linealmente separables, entonces este modelo tiene un gran poder predictivo. Probando una vez más que usar los árboles de decisión como base para algoritmos de ensamble tiene muy buenos resultados.

\begin{table}[]
\centering
\caption{Experimento 2 con conjunto de datos de Apurata}
\label{tab:apurata-proc2}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
ECDD-LR			& 72.56		& 89.76		& 95.96			& 82.86		\\		% AUC std: 3.48
ECDD-MLP	 	& 70.61		& 89.64		& 92.30			& 80.61		\\		% AUC std: 3.49
ECDD-AD			& 68.81		& 89.42		& 92.93			& 80.73		\\		% AUC std: 3.46
ECDD-SVM	 	& 71.70		& 89.81		& 94.44			& 82.04		\\		% AUC std: 3.54
				\hline
RF		 		& 69.23		& 89.37		& 94.57			& 81.66		\\		% AUC std: 3.52
XGB				& 67.91		& 89.31		& 89.92			& 78.75		\\		% AUC std: 3.47
				\hline
\end{tabularx}
\end{table}


\begin{table}[]
\centering
\caption{Experimento 2 con conjunto de datos de LendingClub}
\label{tab:lc-proc2}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
ECDD-LR			& 71.50		& 81.84		& 98.83			& 78.68		\\		% AUC std: 0.12
ECDD-MLP		& 71.61		& 82.44		& 97.08			& 79.00		\\		% AUC std: 0.14
ECDD-AD			& 71.82		& 82.71		& 96.02			& 79.20		\\		% AUC std: 0.12
ECDD-SVM		& 71.49		& 82.27		& 97.88			& 79.35		\\		% AUC std: 0.13
				\hline
RF				& 71.32		& 82.18		& 97.23			& 78.79		\\		% AUC std: 0.14
XGB				& 70.68		& 81.89		& 98.56			& 78.81		\\		% AUC std: 0.12
				\hline
\end{tabularx}
\end{table}


\begin{table}[]
\centering
\caption{Experimento 2 con conjunto de datos Alemán}
\label{tab:german-proc2}
\begin{tabularx}{0.75\textwidth}{|l|Y Y Y Y|}
				\hline
				& AUC		& Precisión	& Exhaust.		& Exactitud	\\
				\hline
ECDD-LR			& 73.34		& 77.55		& 96.23			& 74.85		\\		% AUC std: 2.12
ECDD-MLP		& 75.67		& 79.09		& 94.07			& 75.82		\\		% AUC std: 2.10
ECDD-AD			& 80.34		& 81.88		& 89.50			& 78.05		\\		% AUC std: 2.09
ECDD-SVM		& 74.41		& 78.29		& 95.91			& 75.00		\\		% AUC std: 2.19
				\hline
RF				& 79.82		& 80.84		& 92.01			& 76.22		\\		% AUC std: 2.14
XGB				& 80.28		& 81.43		& 91.66			& 78.93		\\		% AUC std: 2.08
				\hline
\end{tabularx}
\end{table}


\section{Experimento 3} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Los resultados del experimento 3 se pueden ver en las Tablas \ref{tab:lc-proc3} y \ref{tab:german-proc3}. Sólo tenemos resultados para Lending Club y el Cŕedito Alemás puesto que Apurata es un conjunto de datos privado que es usado de forma inédita en este trabajo.

Es importante notar que al haber seguido procesos diferentes, los resultados de diferentes estudios tienen una variación más alta que si se hubieran hecho las comparaciones usando los mismo procesos. Es por esto que las conclusiones del experimento 2 son tan importantes.

Los modelos utilizados en los estudios referenciales son bastante diversos, abarcando modelos lineales y no lineales, de árboles y redes neuronales, llegando incluso a incluir redes neuronales profundas.

Si vemos los resultados a grandes rasgos, se observa que los \ac{ECDD} son efectivamente competitivos con el estado del arte. Con lo cuál podemos concluir que aplicar este método de ensamble para conjuntos de datos desbalanceados al dominio de los puntajes de crédito puede tener resultados bastante interesantes e incluso tener un poder predictivo ligeramente mayor a otros algoritmos más extendidos en la comunidad científica.


\begin{table}[]
\centering
\caption{Experimento 3 con conjunto de datos de LendingClub}
\label{tab:lc-proc3}
\begin{tabularx}{\textwidth}{|l|Y Y l|}
				\hline
				& AUC			& Exactitud		& Ref.									\\
				\hline
ECDD-LR			& 71.50			& 78.68			&										\\		% AUC std: 0.12
ECDD-MLP		& 71.61			& 79.00			&										\\		% AUC std: 0.14
ECDD-AD			& 71.82			& 79.20			&										\\		% AUC std: 0.12
ECDD-SVM		& 71.49			& 79.35			&										\\		% AUC std: 0.13
				\hline
RF				& 71.00			& 78.00			& Malekipirbazari, M.et al (2015)		\\		% No std data
SVM				& 62.00			& 63.30			& Malekipirbazari, M.et al (2015)		\\		% No std data
AD				& -				& 81.22			& Zhang, Y. Et al (2016)				\\		% No std data
NN				& -				& 77.40			& Zhang, Y. Et al (2016)				\\		% No std data
MLP				& -				& 78.60			& Zang, D. et al (2015)					\\		% No std data
crDNN			& 72.55			& -				& Tan, F. et al (2018)					\\		% AUC std: 0.32
LR				& 71.52			& -				& Tan, F. et al (2018)					\\		% AUC std: 0.31
mcDNN			& 70.88			& -				& Tan, F. et al (2018)					\\		% AUC std: 0.28
CRSA			& 69.30			& -				& Tan, F. et al (2018)					\\		% AUC std: 0.44
				\hline
\end{tabularx}
\par
\small
Las investigaciones utilizadas para la comparación son en orden: \citep{malekipirbazari2015risk, zhang2016research, zang2014credit, tan2018deep}
\end{table}


\begin{table}[]
\centering
\caption{Experimento 3 con conjunto de datos Alemán}
\label{tab:german-proc3}
\begin{tabularx}{\textwidth}{|l|Y Y l|}
						\hline
						& AUC		& Exactitud	& Ref.									\\
						\hline
ECDD-LR					& 73.34		& 74.85		&										\\		% AUC std: 2.12
ECDD-MLP				& 75.67		& 75.82		&										\\		% AUC std: 2.10
ECDD-AD					& 80.34		& 78.05		&										\\		% AUC std: 2.09
ECDD-SVM				& 74.41		& 75.00		&										\\		% AUC std: 2.19
						\hline
SVM-linear				& 69.13		& 78.70		& Harris, T. (2015)						\\		% AUC std: 2.94
SVM-RBF					& 69.53		& 78.00		& Harris, T. (2015)						\\		% AUC std: 2.92
CSVM-RBF				& 69.23		& 77.10		& Harris, T. (2015)						\\		% AUC std: 3.17
MLP						& 78.09		& 75.20		& Nanni, L. \& Lumini, A. (2009)		\\		% No std data
Rand Subsp LMNC			& 78.47		& 73.93		& Nanni, L. \& Lumini, A. (2009)		\\		% No std data
Bagging MLP				& 79.32		& 75.33		& Nanni, L. \& Lumini, A. (2009)		\\		% No std data
Class Switch MLP		& 78.62		& 73.93		& Nanni, L. \& Lumini, A. (2009)		\\		% No std data
Rotat Forest MLP		& 79.39		& 75.00		& Nanni, L. \& Lumini, A. (2009)		\\		% No std data
Lin LS-SVM				& 81.90		& -			& Brown, I. \& Mues, C. (2012)			\\		% No std data
Random Forests			& 80.00		& -			& Brown, I. \& Mues, C. (2012)			\\		% No std data
RS-Bagging AD			& -			& 78.36		& Wang, G. et al. (2012)				\\		% No std data
Bagging-RS AD			& -			& 78.52		& Wang, G. et al. (2012)				\\		% No std data
						\hline
\end{tabularx}
\par
\small
Las investigaciones utilizadas para la comparación son en orden: \citep{harris2015credit, nanni2009experimental, brown2012experimental, wang2012two}
\end{table}

